---
title: 机器学习基本点
date: 2018-06-01 10:09:37
tags: [机器学习]
---

# 前言
这是第二遍开始学习机器学习，第一遍都记到本子上，这一次在这里记一次，看看两次记录有哪些异同

# 三要素

## 模型
- 模型可以是条件概率分布
- 模型可以是决策函数

## 策略
- 策略就是考虑按照什么样的规则学习或者选择最优模型。
- 度量模型的好坏可以使用损失函数和风险函数

### 损失函数
损失函数度量**一次**预测的好坏

### 风险函数
风险函数度量**平均意义下**模型预测的好坏

# 损失函数与代价函数的区别

- 损失函数：用来计算单个样本的误差
- 代价函数：与损失函数一样也是计算样本误差的，网上说区别是，代价函数是计算训练集上的所有样本的误差平均数（不过这就跟风险函数重复了不是么？）
- 目标函数：一般来说就是 损失函数 + 正则化项



# 损失函数
损失函数也分了好几种，通常使用 $L(Y, f(X))$

1. 0-1损失函数

$$
L(Y, f(X)) =\begin{cases}
1&       Y \neq f(X)\\
0&       Y = f(X)
\end{cases}
$$

2. 平方损失函数
主要用于最小二乘法

$$
L(Y, f(X)) = {(Y-f(X))}^2
$$

3. 绝对损失函数

$$
L(Y, f(X)) = \vert Y-f(X) \vert
$$

4. 对数(似然)损失函数

$$
L(Y, P(Y|X)) = -\log P(Y|X)
$$

5. 铰链损失函数
主要用于SVM

$$
L(m_i) = \max(0, 1-m_i(w))
$$

6. 互熵函数

主要用于逻辑回归 或者 softmax 中

$$
\begin{array}{l}
L(Y, P(Y|X)) = -\log P(Y|X)\\
P(y=1|x;\theta) = h_\theta(x)\\
P(y=0|x;\theta) = 1 - h_\theta(x)\\
p(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y}
\end{array}
$$

$$
\begin{equation}\begin{split}
L(\theta) &= p(\vec{y}| X;\theta)\\
&= \prod_{i=1}^{m}p(y^{(i)}|x^{(i)};\theta)\\
&= \prod_{i=1}^{m}(h_{\theta}(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}
\end{split}\end{equation}
$$

最大化 $\ell(\theta)$这个$\log$似然函数，就是最小化互熵函数

$$
\begin{equation}\begin{split}
\ell(\theta) &= \log(-L(\theta))\\
&= \frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log h(x^{(i)}) + (1-y^{(i)})\log (1-h(x^{(i)}))
\end{split}\end{equation}
$$

其中，

$$
\begin{equation}\begin{split}
h_\theta(x) = \frac{1}{1-\exp({-f(x)})}
\end{split}\end{equation}
$$

7. 指数函数
主要用于adaboost

## 风险函数
风险函数是损失函数的期望：

$$
R_{exp}(f) = E_{P}[L(Y,f(X))]
$$

由于风险函数无法直接求出，所以可以使用经验损失函数。
经验损失函数 是训练集的平均损失
经验风险最小化，就是最优模型

$$
R_{exp}(f) = E_{P}[L(Y,f(X))]
$$

## 目标函数
为了防止过拟合,提出结构风险函数  $\lambda$作为参数，权衡经验风险和复杂度 $J(f)$是正则化项

$$
R_{\min}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i)) + \lambda J(f)
$$

# 总结

latex 的格式乱了，有时间整理成 图片好了
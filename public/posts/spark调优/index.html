<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="">
<meta name="description" content="Spark 调优 [toc]
前言 发现两篇古老的调优数据，复制一下 原链接
避免创建重复的RDD 通常来说，在开发Spark作业时，
 首先是基于某个数据源创建一个初始RDD 对这个RDD执行算子操作，得到下一个RDD 以此类推，循环上述步骤 得出最终结果  这个过程中通过不同的算子操作(map, reduce等)串起多个RDD,就是 RDD lineage，也就是RDD的血缘关系链
需要注意的是： 对于同一份数据，应该只创建一个RDD，不能创建多个RDD来代表同一个数据
同一份数据创建了多个RDD意味着 spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销
// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。  // 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。 // 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。 // 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。 val rdd1 = sc.textFile(&amp;#34;hdfs://192.168.0.1:9000/hello.txt&amp;#34;) rdd1.map(...) val rdd2 = sc.textFile(&amp;#34;hdfs://192.168.0.1:9000/hello.txt&amp;#34;) rdd2.reduce(...) // 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。 // 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。 // 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。 // 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。 val rdd1 = sc.textFile(&amp;#34;hdfs://192.168.0.1:9000/hello.txt&amp;#34;) rdd1.map(...) rdd1.reduce(...) 尽可能复用一个RDD 在不同的数据执行算子操作时，还要尽可能复用一个RDD。数据有重叠、或者有包含的情况下，应该减少RDD的数量，尽可能减少算子的执行次数
// 错误的做法。  // 有一个&amp;lt;Long, String&amp;gt;格式的RDD，即rdd1。 // 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。 val rdd1: RDD[(Long, String)] = ." />
<meta name="keywords" content=", spark" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="http://keltoy.github.io/posts/spark%E8%B0%83%E4%BC%98/" />


    <title>
        
            spark调优 :: Toy&#39;s Blogs  — 4 Lambda
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="/main.c46cbca46fa76c0fcd3da8313ecf4adee5fb3ffb0288c0902d7e90aead220d79.css">






<meta itemprop="name" content="spark调优">
<meta itemprop="description" content="Spark 调优 [toc]
前言 发现两篇古老的调优数据，复制一下 原链接
避免创建重复的RDD 通常来说，在开发Spark作业时，
 首先是基于某个数据源创建一个初始RDD 对这个RDD执行算子操作，得到下一个RDD 以此类推，循环上述步骤 得出最终结果  这个过程中通过不同的算子操作(map, reduce等)串起多个RDD,就是 RDD lineage，也就是RDD的血缘关系链
需要注意的是： 对于同一份数据，应该只创建一个RDD，不能创建多个RDD来代表同一个数据
同一份数据创建了多个RDD意味着 spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销
// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。  // 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。 // 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。 // 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) val rdd2 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd2.reduce(...) // 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。 // 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。 // 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。 // 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) rdd1.reduce(...) 尽可能复用一个RDD 在不同的数据执行算子操作时，还要尽可能复用一个RDD。数据有重叠、或者有包含的情况下，应该减少RDD的数量，尽可能减少算子的执行次数
// 错误的做法。  // 有一个&lt;Long, String&gt;格式的RDD，即rdd1。 // 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。 val rdd1: RDD[(Long, String)] = ."><meta itemprop="datePublished" content="2020-05-12T15:35:34&#43;00:00" />
<meta itemprop="dateModified" content="2020-05-12T15:35:34&#43;00:00" />
<meta itemprop="wordCount" content="369"><meta itemprop="image" content="http://keltoy.github.io/background-cover.jpg"/>
<meta itemprop="keywords" content="spark," />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://keltoy.github.io/background-cover.jpg"/>

<meta name="twitter:title" content="spark调优"/>
<meta name="twitter:description" content="Spark 调优 [toc]
前言 发现两篇古老的调优数据，复制一下 原链接
避免创建重复的RDD 通常来说，在开发Spark作业时，
 首先是基于某个数据源创建一个初始RDD 对这个RDD执行算子操作，得到下一个RDD 以此类推，循环上述步骤 得出最终结果  这个过程中通过不同的算子操作(map, reduce等)串起多个RDD,就是 RDD lineage，也就是RDD的血缘关系链
需要注意的是： 对于同一份数据，应该只创建一个RDD，不能创建多个RDD来代表同一个数据
同一份数据创建了多个RDD意味着 spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销
// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。  // 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。 // 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。 // 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) val rdd2 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd2.reduce(...) // 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。 // 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。 // 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。 // 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) rdd1.reduce(...) 尽可能复用一个RDD 在不同的数据执行算子操作时，还要尽可能复用一个RDD。数据有重叠、或者有包含的情况下，应该减少RDD的数量，尽可能减少算子的执行次数
// 错误的做法。  // 有一个&lt;Long, String&gt;格式的RDD，即rdd1。 // 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。 val rdd1: RDD[(Long, String)] = ."/>




    <meta property="og:title" content="spark调优" />
<meta property="og:description" content="Spark 调优 [toc]
前言 发现两篇古老的调优数据，复制一下 原链接
避免创建重复的RDD 通常来说，在开发Spark作业时，
 首先是基于某个数据源创建一个初始RDD 对这个RDD执行算子操作，得到下一个RDD 以此类推，循环上述步骤 得出最终结果  这个过程中通过不同的算子操作(map, reduce等)串起多个RDD,就是 RDD lineage，也就是RDD的血缘关系链
需要注意的是： 对于同一份数据，应该只创建一个RDD，不能创建多个RDD来代表同一个数据
同一份数据创建了多个RDD意味着 spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销
// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。  // 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。 // 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。 // 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) val rdd2 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd2.reduce(...) // 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。 // 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。 // 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。 // 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) rdd1.reduce(...) 尽可能复用一个RDD 在不同的数据执行算子操作时，还要尽可能复用一个RDD。数据有重叠、或者有包含的情况下，应该减少RDD的数量，尽可能减少算子的执行次数
// 错误的做法。  // 有一个&lt;Long, String&gt;格式的RDD，即rdd1。 // 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。 val rdd1: RDD[(Long, String)] = ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://keltoy.github.io/posts/spark%E8%B0%83%E4%BC%98/" /><meta property="og:image" content="http://keltoy.github.io/background-cover.jpg"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-12T15:35:34&#43;00:00" />
<meta property="article:modified_time" content="2020-05-12T15:35:34&#43;00:00" /><meta property="og:site_name" content="Toy&#39;s Blogs" />







    <meta property="article:published_time" content="2020-05-12 15:35:34 &#43;0000 UTC" />








    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">READ-EVAL-PRINT-LOOP</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="/about">About</a></li><li><a href="/posts">Blog</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        2 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="http://keltoy.github.io/posts/spark%E8%B0%83%E4%BC%98/">spark调优</a>
      </h1>

      

      

      

      <div class="post-content">
        <h1 id="spark-调优">Spark 调优</h1>
<p>[toc]</p>
<h2 id="前言">前言</h2>
<p>发现两篇古老的调优数据，复制一下 <a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html">原链接</a></p>
<h2 id="避免创建重复的rdd">避免创建重复的RDD</h2>
<p>通常来说，在开发Spark作业时，</p>
<ol>
<li>首先是基于某个数据源创建一个初始RDD</li>
<li>对这个RDD执行算子操作，得到下一个RDD</li>
<li>以此类推，循环上述步骤</li>
<li>得出最终结果</li>
</ol>
<p>这个过程中通过不同的算子操作(map, reduce等)串起多个RDD,就是 RDD lineage，也就是RDD的血缘关系链</p>
<p>需要注意的是： <strong>对于同一份数据，应该只创建一个RDD，不能创建多个RDD来代表同一个数据</strong></p>
<p>同一份数据创建了多个RDD意味着 spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。
</span><span style="color:#75715e"></span>
<span style="color:#75715e">// 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。
</span><span style="color:#75715e">// 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。
</span><span style="color:#75715e">// 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd1 <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://192.168.0.1:9000/hello.txt&#34;</span><span style="color:#f92672">)</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(...)</span>
<span style="color:#66d9ef">val</span> rdd2 <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://192.168.0.1:9000/hello.txt&#34;</span><span style="color:#f92672">)</span>
rdd2<span style="color:#f92672">.</span>reduce<span style="color:#f92672">(...)</span>

<span style="color:#75715e">// 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。
</span><span style="color:#75715e">// 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。
</span><span style="color:#75715e">// 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。
</span><span style="color:#75715e">// 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd1 <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://192.168.0.1:9000/hello.txt&#34;</span><span style="color:#f92672">)</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(...)</span>
rdd1<span style="color:#f92672">.</span>reduce<span style="color:#f92672">(...)</span>
</code></pre></div><h3 id="尽可能复用一个rdd">尽可能复用一个RDD</h3>
<p>在不同的数据执行算子操作时，还要尽可能复用一个RDD。数据有重叠、或者有包含的情况下，应该减少RDD的数量，尽可能减少算子的执行次数</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 错误的做法。
</span><span style="color:#75715e"></span>
<span style="color:#75715e">// 有一个&lt;Long, String&gt;格式的RDD，即rdd1。
</span><span style="color:#75715e">// 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd1<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[(</span><span style="color:#66d9ef">Long</span>, <span style="color:#66d9ef">String</span><span style="color:#f92672">)]</span> <span style="color:#66d9ef">=</span> <span style="color:#f92672">...</span>
<span style="color:#66d9ef">val</span> rdd2<span style="color:#66d9ef">:</span><span style="color:#960050;background-color:#1e0010">[</span><span style="color:#66d9ef">String</span><span style="color:#960050;background-color:#1e0010">]</span><span style="color:#f92672">=</span> rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(...)</span>

<span style="color:#75715e">// 分别对rdd1和rdd2执行了不同的算子操作。
</span><span style="color:#75715e"></span>rdd1<span style="color:#f92672">.</span>reduceByKey<span style="color:#f92672">(...)</span>
rdd2<span style="color:#f92672">.</span>map<span style="color:#f92672">(...)</span>

<span style="color:#75715e">// 正确的做法。
</span><span style="color:#75715e"></span>
<span style="color:#75715e">// 上面这个case中，其实rdd1和rdd2的区别无非就是数据格式不同而已，rdd2的数据完全就是rdd1的子集而已，却创建了两个rdd，并对两个rdd都执行了一次算子操作。
</span><span style="color:#75715e">// 此时会因为对rdd1执行map算子来创建rdd2，而多执行一次算子操作，进而增加性能开销。
</span><span style="color:#75715e"></span>
<span style="color:#75715e">// 其实在这种情况下完全可以复用同一个RDD。
</span><span style="color:#75715e">// 我们可以使用rdd1，既做reduceByKey操作，也做map操作。
</span><span style="color:#75715e">// 在进行第二个map操作时，只使用每个数据的tuple._2，也就是rdd1中的value值，即可。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd1<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[(</span><span style="color:#66d9ef">Long</span>, <span style="color:#66d9ef">String</span><span style="color:#f92672">)]</span> <span style="color:#66d9ef">=</span> <span style="color:#f92672">...</span>
rdd1<span style="color:#f92672">.</span>reduceByKey<span style="color:#f92672">(...)</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(</span>tuple<span style="color:#f92672">.</span>_2<span style="color:#f92672">...)</span>

<span style="color:#75715e">// 第二种方式相较于第一种方式而言，很明显减少了一次rdd2的计算开销。
</span><span style="color:#75715e">// 但是到这里为止，优化还没有结束，对rdd1我们还是执行了两次算子操作，rdd1实际上还是会被计算两次。
</span><span style="color:#75715e">// 因此还需要配合“原则三：对多次使用的RDD进行持久化”进行使用，才能保证一个RDD被多次使用时只被计算一次。
</span></code></pre></div><h3 id="对多次使用的rdd进行持久化">对多次使用的RDD进行持久化</h3>
<p>Spark中对于一个RDD执行多次算子，每次对一个RDD执行一个算子操作时，都会重新从源头处计算一遍，计算出RDD来，然后再对这个RDD执行下一个算子操作。这种方式的性能是很差的。
因此对于这种情况，对多次使用的RDD进行持久化。此时Spark就会根据你的持久化策略，将RDD中的数据保存到内存或者磁盘中。以后每次对这个RDD进行算子操作时，都会直接从内存或磁盘中提取持久化的RDD数据，然后执行算子，而不会从源头处重新计算一遍这个RDD，再执行算子操作。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 如果要对一个RDD进行持久化，只要对这个RDD调用cache()和persist()即可。
</span><span style="color:#75715e"></span>
<span style="color:#75715e">// 正确的做法。
</span><span style="color:#75715e">// cache()方法表示：使用非序列化的方式将RDD中的数据全部尝试持久化到内存中。
</span><span style="color:#75715e">// 此时再对rdd1执行两次算子操作时，只有在第一次执行map算子时，才会将这个rdd1从源头处计算一次。
</span><span style="color:#75715e">// 第二次执行reduce算子时，就会直接从内存中提取数据进行计算，不会重复计算一个rdd。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd1 <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://192.168.0.1:9000/hello.txt&#34;</span><span style="color:#f92672">).</span>cache<span style="color:#f92672">()</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(...)</span>
rdd1<span style="color:#f92672">.</span>reduce<span style="color:#f92672">(...)</span>

<span style="color:#75715e">// persist()方法表示：手动选择持久化级别，并使用指定的方式进行持久化。
</span><span style="color:#75715e">// 比如说，StorageLevel.MEMORY_AND_DISK_SER表示，内存充足时优先持久化到内存中，内存不充足时持久化到磁盘文件中。
</span><span style="color:#75715e">// 而且其中的_SER后缀表示，使用序列化的方式来保存RDD数据，此时RDD中的每个partition都会序列化成一个大的字节数组，然后再持久化到内存或磁盘中。
</span><span style="color:#75715e">// 序列化的方式可以减少持久化的数据对内存/磁盘的占用量，进而避免内存被持久化数据占用过多，从而发生频繁GC。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd1 <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://192.168.0.1:9000/hello.txt&#34;</span><span style="color:#f92672">).</span>persist<span style="color:#f92672">(</span><span style="color:#a6e22e">StorageLevel</span><span style="color:#f92672">.</span><span style="color:#a6e22e">MEMORY_AND_DISK_SER</span><span style="color:#f92672">)</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(...)</span>
rdd1<span style="color:#f92672">.</span>reduce<span style="color:#f92672">(...)</span>
</code></pre></div><p>持久化级别</p>
<table>
<thead>
<tr>
<th style="text-align:center">持久化级别</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">MEMORY_ONLY</td>
<td style="text-align:center">使用未序列化的Java对象格式，将数据保存在内存中。如果内存不够存放所有的数据，则数据可能就不会进行持久化。那么下次对这个RDD执行算子操作时，那些没有被持久化的数据，需要从源头处重新计算一遍。这是默认的持久化策略，使用cache()方法时，实际就是使用的这种持久化策略。</td>
</tr>
<tr>
<td style="text-align:center">MEMORY_AND_DISK</td>
<td style="text-align:center">使用未序列化的Java对象格式，优先尝试将数据保存在内存中。如果内存不够存放所有的数据，会将数据写入磁盘文件中，下次对这个RDD执行算子时，持久化在磁盘文件中的数据会被读取出来使用。</td>
</tr>
<tr>
<td style="text-align:center">MEMORY_ONLY_SER</td>
<td style="text-align:center">基本含义同MEMORY_ONLY。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。</td>
</tr>
<tr>
<td style="text-align:center">MEMORY_AND_DISK_SER</td>
<td style="text-align:center">基本含义同MEMORY_AND_DISK。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。</td>
</tr>
<tr>
<td style="text-align:center">DISK_ONLY</td>
<td style="text-align:center">使用未序列化的Java对象格式，将数据全部写入磁盘文件中。</td>
</tr>
<tr>
<td style="text-align:center">MEMORY_ONLY_2, MEMORY_AND_DISK_2, 等等.</td>
<td style="text-align:center">对于上述任意一种持久化策略，如果加上后缀_2，代表的是将每个持久化的数据，都复制一份副本，并将副本保存到其他节点上。这种基于副本的持久化机制主要用于进行容错。假如某个节点挂掉，节点的内存或磁盘中的持久化数据丢失了，那么后续对RDD计算时还可以使用该数据在其他节点上的副本。如果没有副本的话，就只能将这些数据从源头处重新计算一遍了。</td>
</tr>
</tbody>
</table>
<ol>
<li>默认情况下，性能最高的当然是MEMORY_ONLY，但前提是你的内存必须足够足够大，可以绰绰有余地存放下整个RDD的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个RDD的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种策略的场景还是有限的，如果RDD中数据比较多时（比如几十亿），直接用这种持久化级别，会导致JVM的OOM内存溢出异常。</li>
<li>如果使用MEMORY_ONLY级别时发生了内存溢出，那么建议尝试使用MEMORY_ONLY_SER级别。该级别会将RDD数据序列化后再保存在内存中，此时每个partition仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别比MEMORY_ONLY多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问题同上，如果RDD中的数据量过多的话，还是可能会导致OOM内存溢出的异常。</li>
<li>如果纯内存的级别都无法使用，那么建议使用MEMORY_AND_DISK_SER策略，而不是MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。</li>
<li>通常不建议使用DISK_ONLY和后缀为_2的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，有时还不如重新计算一次所有RDD。后缀为_2的级别，必须将所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建议使用。</li>
</ol>
<h3 id="尽量避免使用shuffle类算子">尽量避免使用shuffle类算子</h3>
<p>因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。</p>
<p>shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。</p>
<p>因此在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 传统的join操作会导致shuffle操作。
</span><span style="color:#75715e">// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd3 <span style="color:#66d9ef">=</span> rdd1<span style="color:#f92672">.</span>join<span style="color:#f92672">(</span>rdd2<span style="color:#f92672">)</span>

<span style="color:#75715e">// Broadcast+map的join操作，不会导致shuffle操作。
</span><span style="color:#75715e">// 使用Broadcast将一个数据量较小的RDD作为广播变量。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd2Data <span style="color:#66d9ef">=</span> rdd2<span style="color:#f92672">.</span>collect<span style="color:#f92672">()</span>
<span style="color:#66d9ef">val</span> rdd2DataBroadcast <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>broadcast<span style="color:#f92672">(</span>rdd2Data<span style="color:#f92672">)</span>

<span style="color:#75715e">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。
</span><span style="color:#75715e">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。
</span><span style="color:#75715e">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> rdd3 <span style="color:#66d9ef">=</span> rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(</span>rdd2DataBroadcast<span style="color:#f92672">.</span>value<span style="color:#f92672">...)</span>

<span style="color:#75715e">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。
</span><span style="color:#75715e">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。
</span></code></pre></div><h3 id="使用map-side预聚合的shuffle操作">使用map-side预聚合的shuffle操作</h3>
<p>如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。</p>
<p>所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</p>
<p>比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。</p>
<p><img src="/5ebe0848.png" alt="&hellip;..png">
<img src="/a6c7d4c4.png" alt="老八秘制小汉堡.png"></p>
<h3 id="使用高性能算子">使用高性能算子</h3>
<ul>
<li>使用reduceByKey/aggregateByKey替代groupByKey</li>
</ul>
<p>详情见“原则五：使用map-side预聚合的shuffle操作”。</p>
<ul>
<li>使用mapPartitions替代普通map</li>
</ul>
<p>mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！</p>
<ul>
<li>使用foreachPartitions替代foreach</li>
</ul>
<p>原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。</p>
<ul>
<li>使用filter之后进行coalesce操作</li>
</ul>
<p>通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。</p>
<ul>
<li>使用repartitionAndSortWithinPartitions替代repartition与sort类操作</li>
</ul>
<p>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</p>
<h3 id="广播大变量">广播大变量</h3>
<p>有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。</p>
<p>在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。</p>
<p>因此对于上述情况，如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低GC的频率。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 以下代码在算子函数中，使用了外部的变量。
</span><span style="color:#75715e">// 此时没有做任何特殊操作，每个task都会有一份list1的副本。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> list1 <span style="color:#66d9ef">=</span> <span style="color:#f92672">...</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(</span>list1<span style="color:#f92672">...)</span>

<span style="color:#75715e">// 以下代码将list1封装成了Broadcast类型的广播变量。
</span><span style="color:#75715e">// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。
</span><span style="color:#75715e">// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。
</span><span style="color:#75715e">// 每个Executor内存中，就只会驻留一份广播变量副本。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> list1 <span style="color:#66d9ef">=</span> <span style="color:#f92672">...</span>
<span style="color:#66d9ef">val</span> list1Broadcast <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>broadcast<span style="color:#f92672">(</span>list1<span style="color:#f92672">)</span>
rdd1<span style="color:#f92672">.</span>map<span style="color:#f92672">(</span>list1Broadcast<span style="color:#f92672">...)</span>
</code></pre></div><h3 id="使用kyro优化序列化性能">使用kyro优化序列化性能</h3>
<p>在Spark中，主要有三个地方涉及到了序列化：</p>
<ul>
<li>在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输</li>
<li>将自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。</li>
<li>使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。</li>
</ul>
<p>对于这三种出现的序列化，都可以通过使用Kryo序列化类库来优化序列化和反序列化的性能。Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream / ObjectInputStream API来进行序列化和反序列化</p>
<p>但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦</p>
<p>以下是使用Kryo的代码示例，我们只要设置序列化类，再注册要序列化的自定义类型即可（比如算子函数中使用到的外部变量类型、作为RDD泛型类型的自定义类型等）：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#75715e">// 创建SparkConf对象。
</span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> conf <span style="color:#66d9ef">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">SparkConf</span><span style="color:#f92672">().</span>setMaster<span style="color:#f92672">(...).</span>setAppName<span style="color:#f92672">(...)</span>
<span style="color:#75715e">// 设置序列化器为KryoSerializer。
</span><span style="color:#75715e"></span>conf<span style="color:#f92672">.</span>set<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;spark.serializer&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;org.apache.spark.serializer.KryoSerializer&#34;</span><span style="color:#f92672">)</span>
<span style="color:#75715e">// 注册要序列化的自定义类型。
</span><span style="color:#75715e"></span>conf<span style="color:#f92672">.</span>registerKryoClasses<span style="color:#f92672">(</span><span style="color:#a6e22e">Array</span><span style="color:#f92672">(</span>classOf<span style="color:#f92672">[</span><span style="color:#66d9ef">MyClass1</span><span style="color:#f92672">],</span> classOf<span style="color:#f92672">[</span><span style="color:#66d9ef">MyClass2</span><span style="color:#f92672">]))</span>
</code></pre></div><h3 id="优化数据结构">优化数据结构</h3>
<p>Java中，有三种类型比较耗费内存：</p>
<ul>
<li>对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。</li>
<li>字符串，每个字符串内部都有一个字符数组以及长度等额外信息。</li>
<li>集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如Map.Entry</li>
</ul>
<p>因此Spark官方建议，在Spark编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型（比如Int、Long）替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用，从而降低GC频率，提升性能。</p>
<p>但是在实践中发现，要做到该原则其实并不容易。因为我们同时要考虑到代码的可维护性，如果一个代码中，完全没有任何对象抽象，全部是字符串拼接的方式，那么对于后续的代码维护和修改，无疑是一场巨大的灾难。同理，如果所有操作都基于数组实现，而不使用HashMap、LinkedList等集合类型，那么对于我们的编码难度以及代码可维护性，也是一个极大的挑战。因此笔者建议，在可能以及合适的情况下，使用占用内存较少的数据结构，但是前提是要保证代码的可维护性。</p>
<h3 id="运行原理">运行原理</h3>
<p><img src="/1f1ddad5.png" alt="1f1ddad5.png"></p>
<ol>
<li>我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。</li>
<li>根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。</li>
<li>而Driver进程要做的第一件事情，就是向集群管理器申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。</li>
<li>YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。</li>
<li>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。</li>
<li>一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。</li>
</ol>
<p>Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。</p>
<p>当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。</p>
<p>因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。</p>
<p>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。</p>
<p>以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。</p>
<h3 id="参数调优">参数调优</h3>
<ul>
<li>
<p>num-executors</p>
<ul>
<li>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。</li>
<li>参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源</li>
</ul>
</li>
<li>
<p>executor-memory</p>
<ul>
<li>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。</li>
<li>参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</li>
</ul>
</li>
<li>
<p>executor-cores</p>
<ul>
<li>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。</li>
<li>参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。</li>
</ul>
</li>
<li>
<p>driver-memory</p>
<ul>
<li>参数说明：该参数用于设置Driver进程的内存。</li>
<li>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</li>
</ul>
</li>
<li>
<p>spark.default.parallelism</p>
<ul>
<li>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</li>
<li>参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</li>
</ul>
</li>
<li>
<p>spark.storage.memoryFraction</p>
<ul>
<li>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</li>
<li>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li>
</ul>
</li>
<li>
<p>spark.shuffle.memoryFraction</p>
<ul>
<li>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</li>
<li>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li>
</ul>
</li>
</ul>
<p>资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。</p>
<p>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./bin/spark-submit <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --master yarn-cluster <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --num-executors <span style="color:#ae81ff">100</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --executor-memory 6G <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --executor-cores <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --driver-memory 1G <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --conf spark.default.parallelism<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --conf spark.storage.memoryFraction<span style="color:#f92672">=</span>0.5 <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --conf spark.shuffle.memoryFraction<span style="color:#f92672">=</span>0.3 <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  
  
  --conf spark.dynamicAllocation.enabled<span style="color:#f92672">=</span> true //开启动态资源分配
  --conf spark.dynamicAllocation.minExecutors<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> //每个Application最小分配的executor数
  --conf spark.dynamicAllocation.maxExecutors<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span> //每个Application最大并发分配的executor数
</code></pre></div><p>如果开启了动态资源分配，那么需要去掉 &ndash;num-executors 的参数，否则动态资源分配不会有效果</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="http://keltoy.github.io/tags/spark/">spark</a></span>
        
    </p>

      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        369 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2020-05-12 23:35 &#43;0800
        

         
          
        
      </p>
    </div>
      <hr />
      <div class="sharing-buttons">
        
<a class="resp-sharing-button__link" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_blank" rel="noopener" aria-label="" title="Share on facebook">
  <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?url=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_blank" rel="noopener" aria-label="" title="Share on twitter">
  <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small">
      <div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.tumblr.com/widgets/share/tool?posttype=link&amp;title=spark%e8%b0%83%e4%bc%98&amp;caption=spark%e8%b0%83%e4%bc%98&amp;canonicalUrl=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_blank" rel="noopener" aria-label="" title="Share on tumblr">
  <div class="resp-sharing-button resp-sharing-button--tumblr resp-sharing-button--small">
    <div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14.563 24c-5.093 0-7.031-3.756-7.031-6.411V9.747H5.116V6.648c3.63-1.313 4.512-4.596 4.71-6.469C9.84.051 9.941 0 9.999 0h3.517v6.114h4.801v3.633h-4.82v7.47c.016 1.001.375 2.371 2.207 2.371h.09c.631-.02 1.486-.205 1.936-.419l1.156 3.425c-.436.636-2.4 1.374-4.156 1.404h-.178l.011.002z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="mailto:?subject=spark%e8%b0%83%e4%bc%98&amp;body=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_self" rel="noopener" aria-label="" title="Share via email">
  <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://pinterest.com/pin/create/button/?url=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f&amp;media=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f;description=spark%e8%b0%83%e4%bc%98" target="_blank" rel="noopener" aria-label="" title="Share on pinterest">
  <div class="resp-sharing-button resp-sharing-button--pinterest resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M12.017 0C5.396 0 .029 5.367.029 11.987c0 5.079 3.158 9.417 7.618 11.162-.105-.949-.199-2.403.041-3.439.219-.937 1.406-5.957 1.406-5.957s-.359-.72-.359-1.781c0-1.663.967-2.911 2.168-2.911 1.024 0 1.518.769 1.518 1.688 0 1.029-.653 2.567-.992 3.992-.285 1.193.6 2.165 1.775 2.165 2.128 0 3.768-2.245 3.768-5.487 0-2.861-2.063-4.869-5.008-4.869-3.41 0-5.409 2.562-5.409 5.199 0 1.033.394 2.143.889 2.741.099.12.112.225.085.345-.09.375-.293 1.199-.334 1.363-.053.225-.172.271-.401.165-1.495-.69-2.433-2.878-2.433-4.646 0-3.776 2.748-7.252 7.92-7.252 4.158 0 7.392 2.967 7.392 6.923 0 4.135-2.607 7.462-6.233 7.462-1.214 0-2.354-.629-2.758-1.379l-.749 2.848c-.269 1.045-1.004 2.352-1.498 3.146 1.123.345 2.306.535 3.55.535 6.607 0 11.985-5.365 11.985-11.987C23.97 5.39 18.592.026 11.985.026L12.017 0z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f&amp;title=spark%e8%b0%83%e4%bc%98&amp;summary=spark%e8%b0%83%e4%bc%98&amp;source=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_blank" rel="noopener" aria-label="" title="Share on linkedin">
  <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f&amp;resubmit=true&amp;title=spark%e8%b0%83%e4%bc%98" target="_blank" rel="noopener" aria-label="" title="Share on reddit">
  <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M12 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0zm5.01 4.744c.688 0 1.25.561 1.25 1.249a1.25 1.25 0 0 1-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968 0 1.754.786 1.754 1.754 0 .716-.435 1.333-1.01 1.614a3.111 3.111 0 0 1 .042.52c0 2.694-3.13 4.87-7.004 4.87-3.874 0-7.004-2.176-7.004-4.87 0-.183.015-.366.043-.534A1.748 1.748 0 0 1 4.028 12c0-.968.786-1.754 1.754-1.754.463 0 .898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342 0 0 1 .14-.197.35.35 0 0 1 .238-.042l2.906.617a1.214 1.214 0 0 1 1.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687 0 1.248-.561 1.248-1.249 0-.688-.561-1.249-1.249-1.249zm5.5 0c-.687 0-1.248.561-1.248 1.25 0 .687.561 1.248 1.249 1.248.688 0 1.249-.561 1.249-1.249 0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327 0 0 0-.231.094.33.33 0 0 0 0 .463c.842.842 2.484.913 2.961.913.477 0 2.105-.056 2.961-.913a.361.361 0 0 0 .029-.463.33.33 0 0 0-.464 0c-.547.533-1.684.73-2.512.73-.828 0-1.979-.196-2.512-.73a.326.326 0 0 0-.232-.095z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.xing.com/app/user?op=share;url=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f;title=spark%e8%b0%83%e4%bc%98" target="_blank" rel="noopener" aria-label="" title="Share on xing">
  <div class="resp-sharing-button resp-sharing-button--xing resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M18.188 0c-.517 0-.741.325-.927.66 0 0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211 0 .375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016 0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894 0 21.686 0h-3.498zM3.648 4.74c-.211 0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016 0 .021L1.86 16.051c-.099.188-.093.381 0 .529.085.142.239.234.45.234h3.461c.518 0 .766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="whatsapp://send?text=spark%e8%b0%83%e4%bc%98%20http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_blank" rel="noopener" aria-label="" title="Share on whatsapp">
  <div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198 0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479 0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87 0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86 0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64 0 5.122 1.03 6.988 2.898a9.825 9.825 0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815 0 0012.05 0C5.495 0 .16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882 0 005.683 1.448h.005c6.554 0 11.89-5.335 11.893-11.893a11.821 11.821 0 00-3.48-8.413Z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://news.ycombinator.com/submitlink?u=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f&amp;t=spark%e8%b0%83%e4%bc%98" target="_blank" rel="noopener" aria-label="" title="Share on hacker news">
  <div class="resp-sharing-button resp-sharing-button--hackernews resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M0 24V0h24v24H0zM6.951 5.896l4.112 7.708v5.064h1.583v-4.972l4.148-7.799h-1.749l-2.457 4.875c-.372.745-.688 1.434-.688 1.434s-.297-.708-.651-1.434L8.831 5.896h-1.88z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://telegram.me/share/url?text=spark%e8%b0%83%e4%bc%98&amp;url=http%3a%2f%2fkeltoy.github.io%2fposts%2fspark%25E8%25B0%2583%25E4%25BC%2598%2f" target="_blank" rel="noopener" aria-label="" title="Share on telegram">
  <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="22" y1="2" x2="11" y2="13"></line><polygon points="22 2 15 22 11 13 2 9 22 2"></polygon></svg>
    </div>
  </div>
</a>

      </div>

    
    <div class="pagination">
        <div class="pagination__title">
            <span class="pagination__title-h">Read other posts</span>
            <hr />
        </div>

        <div class="pagination__buttons">
            
            <span class="button previous">
                <a href="http://keltoy.github.io/posts/spark-shuffle-%E5%92%8C%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/">
                    <span class="button__icon">←</span>
                    <span class="button__text">spark shuffle 和数据倾斜</span>
                </a>
            </span>
            

            
            <span class="button next">
                <a href="http://keltoy.github.io/posts/maven-plugins/">
                    <span class="button__text">maven plugins</span>
                    <span class="button__icon">→</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="/bundle.min.599099f1f14b78b657d524b28e10e0c5098e7cd46e9c7aed73d577068a276c3ff1bb234cbf29cb313333e83cf411727b43157c91ce5b809e2ffc81664614608e.js" integrity="sha512-WZCZ8fFLeLZX1SSyjhDgxQmOfNRunHrtc9V3BoonbD/xuyNMvynLMTMz6Dz0EXJ7QxV8kc5bgJ4v/IFmRhRgjg=="></script>



    </body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on Toy&#39;s Blogs</title>
    <link>http://keltoy.github.io/tags/spark/</link>
    <description>Recent content in spark on Toy&#39;s Blogs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Tue, 12 May 2020 20:39:43 +0000</lastBuildDate><atom:link href="http://keltoy.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>spark shuffle 和数据倾斜</title>
      <link>http://keltoy.github.io/posts/spark-shuffle-%E5%92%8C%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/</link>
      <pubDate>Tue, 12 May 2020 20:39:43 +0000</pubDate>
      
      <guid>http://keltoy.github.io/posts/spark-shuffle-%E5%92%8C%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/</guid>
      <description>[toc]
前言 这是复制过来的第二篇文章，专门讲如何处理数据倾斜问题的 原链接
数据倾斜 现象  绝大多数task 执行非常快，但个别task执行极慢。比如，总共有1000个task，997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时。这种情况很常见。 原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，观察异常栈，是我们写的业务代码造成的。这种情况比较少见。  发生原理 数据倾斜的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。
比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。
因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。
下图就是一个很清晰的例子：hello这个key，在三个节点上对应了总共7条数据，这些数据都会被拉取到同一个task中进行处理；而world和you这两个key分别才对应1条数据，所以另外两个task只要分别处理1条数据即可。此时第一个task的运行时间可能是另外两个task的7倍，而整个stage的运行速度也由运行最慢的那个task所决定。
定位代码 数据倾斜只会发生在shuffle过程中。一些常用的并且可能会触发shuffle操作的算子：
 distinct groupByKey reduceByKey aggregateByKey join cogroup repartition等。  出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。
某个task执行特别慢的情况 首先要看的，就是数据倾斜发生在第几个stage中。
可以通过Spark Web UI来查看当前运行到了第几个stage。此外，无论是使用yarn-client模式还是yarn-cluster模式，我们都可以在Spark Web UI上深入看一下当前这个stage各个task分配的数据量，从而进一步确定是不是task分配的数据不均匀导致了数据倾斜。
知道数据倾斜发生在哪一个stage之后，接着我们就需要根据stage划分原理，推算出来发生倾斜的那个stage对应代码中的哪一部分，这部分代码中肯定会有一个shuffle类算子。精准推算stage与代码的对应关系，需要对Spark的源码有深入的理解，这里我们可以介绍一个相对简单实用的推算方法：只要看到Spark代码中出现了一个shuffle类算子或者是Spark SQL的SQL语句中出现了会导致shuffle的语句（比如group by语句），那么就可以判定，以那个地方为界限划分出了前后两个stage。
这里我们就以Spark最基础的入门程序——单词计数来举例，如何用最简单的方法大致推算出一个stage对应的代码。如下示例，在整个代码中，只有一个reduceByKey是会发生shuffle的算子，因此就可以认为，以这个算子为界限，会划分出前后两个stage。
 stage0，主要是执行从textFile到map操作，以及执行shuffle write操作。shuffle write操作，我们可以简单理解为对pairs RDD中的数据进行分区操作，每个task处理的数据中，相同的key会写入同一个磁盘文件内。 stage1，主要是执行从reduceByKey到collect操作，stage1的各个task一开始运行，就会首先执行shuffle read操作。执行shuffle read操作的task，会从stage0的各个task所在节点拉取属于自己处理的那些key，然后对同一个key进行全局性的聚合或join等操作，在这里就是对key的value值进行累加。stage1在执行完reduceByKey算子之后，就计算出了最终的wordCounts RDD，然后会执行collect算子，将所有数据拉取到Driver上，供我们遍历和打印输出。  val conf = new SparkConf() val sc = new SparkContext(conf) val lines = sc.textFile(&amp;#34;hdfs://...&amp;#34;) val words = lines.flatMap(_.split(&amp;#34; &amp;#34;)) val pairs = words.</description>
    </item>
    
    <item>
      <title>spark调优</title>
      <link>http://keltoy.github.io/posts/spark%E8%B0%83%E4%BC%98/</link>
      <pubDate>Tue, 12 May 2020 15:35:34 +0000</pubDate>
      
      <guid>http://keltoy.github.io/posts/spark%E8%B0%83%E4%BC%98/</guid>
      <description>Spark 调优 [toc]
前言 发现两篇古老的调优数据，复制一下 原链接
避免创建重复的RDD 通常来说，在开发Spark作业时，
 首先是基于某个数据源创建一个初始RDD 对这个RDD执行算子操作，得到下一个RDD 以此类推，循环上述步骤 得出最终结果  这个过程中通过不同的算子操作(map, reduce等)串起多个RDD,就是 RDD lineage，也就是RDD的血缘关系链
需要注意的是： 对于同一份数据，应该只创建一个RDD，不能创建多个RDD来代表同一个数据
同一份数据创建了多个RDD意味着 spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销
// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。  // 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。 // 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。 // 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。 val rdd1 = sc.textFile(&amp;#34;hdfs://192.168.0.1:9000/hello.txt&amp;#34;) rdd1.map(...) val rdd2 = sc.textFile(&amp;#34;hdfs://192.168.0.1:9000/hello.txt&amp;#34;) rdd2.reduce(...) // 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。 // 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。 // 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。 // 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。 val rdd1 = sc.textFile(&amp;#34;hdfs://192.168.0.1:9000/hello.txt&amp;#34;) rdd1.map(...) rdd1.reduce(...) 尽可能复用一个RDD 在不同的数据执行算子操作时，还要尽可能复用一个RDD。数据有重叠、或者有包含的情况下，应该减少RDD的数量，尽可能减少算子的执行次数
// 错误的做法。  // 有一个&amp;lt;Long, String&amp;gt;格式的RDD，即rdd1。 // 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。 val rdd1: RDD[(Long, String)] = .</description>
    </item>
    
  </channel>
</rss>
